---
title: "HW1"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(patchwork)
```

## Question 1

### Question 1(b)
```{r chunk_Q1b, message=FALSE, warning=FALSE}
k1 = 600
k2 = 300
rho_1 = 0.2
rho_2 = 0.5
rho_3 = 0.8
rho = c(rho_1, rho_2, rho_3)
V_a = c(1, 1, 1)*4/k1
V_b = c(1, 1, 1)*8*(1-rho)/k2
V_c = c(1, 1, 1)*2*(1-rho)/k2
V_d = c(1, 1, 1)*2*(rho+1)/k2
b  = cbind(rho, V_a, V_b, V_c, V_d) %>% as.data.frame()
options(digits = 2)
print(b)
```
For minimum variance, for any $\rho$, I would always choose Crossover study to minimize uncertainty.

### Question 1(c)
```{r chunk_Q1c, message=FALSE, warning=FALSE}
k1 = 600
k2 = 400
rho_1 = 0.2
rho_2 = 0.5
rho_3 = 0.8
rho = c(rho_1, rho_2, rho_3)
V_a = c(1, 1, 1)*4/k1
V_b = c(1, 1, 1)*8*(1-rho)/k2
V_c = c(1, 1, 1)*2*(1-rho)/k2
V_d = c(1, 1, 1)*2*(rho+1)/k2
c  = cbind(rho, V_a, V_b, V_c, V_d) %>% as.data.frame()
options(digits = 2)
print(c)
```
For minimum variance, for any $\rho$, I would always choose Crossover study to minimize uncertainty.

## Question 2

### Question 2(a)
```{r chunk_Q2a, message=FALSE, warning=FALSE}
load("~/Documents/2023Fall/P8157/P8157/Six Cities.RData")
# data summmary
nrow(topeka) # number of total observations
length(unique(topeka$id)) # number of clusters
visit = topeka %>% group_by(id) %>%tally() 
summary(visit$n) # summary of observations in one cluster
skimr::skim(topeka) %>% tibble::as_tibble() # summary of variables
# outlier
box = topeka %>% ggplot(aes(x = log.FEV1)) + geom_boxplot() 
# dependence
pair = pairs(topeka) 
cor = corrplot::corrplot(cor(topeka[]))
# spaghetti plot
ggplot(topeka, aes(x = height, y = log.FEV1, group = id, color = id)) + 
  geom_line() +
  scale_y_continuous(limits = c(-0.25, 1.5)) 
# exploratory
g1 = ggplot(topeka, aes(x = height, y = log.FEV1)) + 
  geom_point() +
  scale_y_continuous(limits = c(-0.25, 1.5)) 
g2 = ggplot(topeka, aes(x = height - height.init, y = log.FEV1)) + 
  geom_point() +
  scale_y_continuous(limits = c(-0.25, 1.5)) 
g3 = ggplot(topeka, aes(x = age, y = log.FEV1)) + 
  geom_point() +
  scale_y_continuous(limits = c(-0.25, 1.5)) 
g1 + g2+ g3
```

There are 5 variables and 1 outcome in the topeka dataset, which consists of 300 clusters with 1994 measurements. Number of measurements within each cluster ranges from 1 to 12, with mean being 6.6 and median being 7. The mean age of the subjects upon their recruitment was 8.03, while the height was 1.28m. For simplicity, the age and height variables could be standardized when conducting the longitudal analysis. One outlier of the outcome log.FEV1 was observed which should be further investigated. In the correlation plot one can see that the covariates age and height are highly correlated, indicating they might be dependent of each other. 

From the scatterplot we can tell that there exists association between age, height, height change and log.FEV1. log.FEV1 seems to be positive related to all the three variables. 



### Question 2(b)

If we take log.FEV1 as the outcome, we can test if the increase in log.FEV1 is associated with the increase in height. As we can see from the scatterplot that larger increase in height might indicate higher log.FEV1.

### Question 2(c)
```{r message=FALSE, warning=FALSE}
ggplot(topeka, aes(x = scale(height.init), y = log.FEV1)) + 
  geom_point() +
  scale_y_continuous(limits = c(-0.25, 1.5)) 
```

Using cross-sectional data at baseline, we could explore the relationship between initial height and log.FEV1. Assumptions could be made from the scatterplot that those with higher initial height are unlikely to have relative low log.FEV1. 


## Question 3

```{r}
load("~/Documents/2023Fall/P8157/P8157/MACS.RData")
dmm = macs %>%
  filter(time >= -0.5) %>% 
  group_by(id) %>%
  filter(any(-0.5 <= time & time < 0) && any(time > 0)) %>%
  mutate(visit = row_number() - 1) %>%
  ungroup() 
```
### Question 3(a)

Here's Table 1 summarizing the covariates at baseline:
```{r message=FALSE, warning=FALSE}
sum = skimr::skim(dmm) %>% tibble::as_tibble()
sum
dmm = dmm %>% 
  group_by(id) %>%
  mutate(idd = group_indices()) %>%
  ungroup() 
```

### Question 3(b)

Here's the spaghetti plot of the CD4+ cell count progression across time since seroconversion:
```{r}
K = 266
# spaghetti plot
ggplot(dmm, aes(x = time, y = cd4, group = id, color = id)) + 
  geom_line()
```

#### Stage 1: Coefficients table (first 6 rows) for time (LogNormal model): 
```{r}
# Stage 1
betaMat = data.frame(beta0=rep(NA, K), beta.time=rep(NA, K))
for(k in 1:K) {
  temp.k = dmm[dmm$idd == k,]
  fit.k = lm(log(cd4) ~ time , data = temp.k)
  betaMat[k, 1:2] = c(fit.k$coef)
}
head(betaMat)
```

#### Stage 2: Explain variance across subject-specific baseline covariates:
```{r}
# Stage 2
dmm_base = dmm %>% 
  filter(visit == 0)
dmm_base$beta.time = betaMat$beta.time
summary(lm(beta.time ~ age + packs + drug + partners + cesd, data=dmm_base))
# In addition, provide a brief summary of the results using language that would be suitable for a non-biostatistician collaborator.
```

As time progresses since seroconversion, the CD4+ cell counts of our patients decrease. The decrease rate could be possibly related to the baseline age; packs of cigarettes per day; whether on drug or not; number of partners and cesd depression level of the patients. If our significance level was set higher, say, 0.1, we would find that the more depressed our patients are, the more CD4+ cells he would lose as time progresses. 

