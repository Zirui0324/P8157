---
title: "Code Appendix"
output: 
  pdf_document:
    number_sections: true
---

```{r setup, message=FALSE}
library(tidyverse)
library(ggplot2)
library(patchwork)
library(nlme)
library(lme4)
```

```{r chunk_data import, message=FALSE}
# load data and data preparation
load("~/Documents/2023Fall/P8157/P8157/Six Cities.RData")
data = topeka |>  group_by(id) |> filter(n() >= 5) |> ungroup()
length(unique(data$id))
data = data |> 
  mutate(y = exp(log.FEV1)/(height^2),
         age.2 = age^2,
         age.3 = age^3)
```

```{r chunk_sample, message=FALSE}
# random sample of 4, plot
set.seed(200324)
sample = data  |> 
  filter(id %in% sample(unique(data$id), 4))
p = ggplot(data, aes(x = age, y = y, group = id, color = id)) + 
  geom_line() +  
  geom_line(data = sample, color = "green") +
  theme_classic()
```

```{r chunk_model fitting}
# 1 naivee
fit1.ML = glm(y ~ age + age.2 + age.3, data, family=gaussian)
# 2 randon intercept + independent error
fit2.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), data, method="ML")
# 3 random intercept/slope + independent error
fit3.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ age | id, pdClass="pdDiag"), data, method="ML")
# 4. random intercept + auto_regressive error
fit4.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), correlation=corAR1(form= ~ age| id), data, method="ML")
# 5 random intercept + exponential spatial error
fit5.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), correlation=corExp(form= ~ age| id), data, method="ML")
# 6 random intercept + exponential spatial error + independent homo error
fit6.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), correlation=corExp(form= ~ age| id, nugget=TRUE), data, method="ML")
# 7 random intercept + independent hetero error
data_cat = data |> 
  dplyr::mutate(age.cat = floor(age/2))
fit7.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), weights=varIdent(form= ~1 | age.cat), data_cat, method="ML")
# 8 random intercept/slope + independent hetero error
fit8.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ age | id), weights=varIdent(form= ~1 | age.cat), data_cat, method="ML")
```

```{r chunk_model summary}
# model summary and comparison
sum = (data.frame(
  logLik = c(logLik(fit1.ML), logLik(fit2.ML), logLik(fit3.ML),logLik(fit4.ML),
             logLik(fit5.ML), logLik(fit6.ML), logLik(fit7.ML), logLik(fit8.ML)),
  AIC = c(AIC(fit1.ML),AIC(fit2.ML),AIC(fit3.ML),AIC(fit4.ML),
          AIC(fit5.ML),AIC(fit6.ML),AIC(fit7.ML),AIC(fit8.ML))
))
colnames(sum) = c("log-Like", "AIC")
rownames(sum) = c("0. Independence", "1. Random intercept + inde. errors", 
                  "2. Random intercept/slope + inde. errors", "3. Random intercept + AR errors",
                  "4. Random intercept + ES errors", "5. Random intercept + ES with a 'nugget'",
                  "6. Random intercept + heteroske inde. errors",
                  "7. Random intercept/slope + heteroske inde. errors")
```

```{r chunk_coef table}
# coefficient summary for model4&5
coef = t((data.frame(
  fit5 = c(summary(fit5.ML)$coefficients$fixed, sqrt(diag(summary(fit5.ML)$varFix))),
  fit6  = c(summary(fit6.ML)$coefficients$fixed, sqrt(diag(summary(fit6.ML)$varFix)))
)))
rownames(coef) = c("Model.4", "Model.5")
colnames(coef) = c("b0", "b1", "b2", "b3",
                   "sd(b0)", "sd(b1)", "sd(b2)", "sd(b3)")
```

```{r}
# fit6.ML = lme(fixed=y ~ age + age.2 + age.3, random=reStruct(~ 1 | id), correlation=corExp(form= ~ age| id, nugget=TRUE), data, method="ML")
fit9.ML = lme(fixed=y ~ age, random=reStruct(~ 1 | id), correlation=corExp(form= ~ age| id, nugget=TRUE), data, method="ML")
predict.1 = predict(fit6.ML, sample)
predict.2 = predict(fit9.ML, sample)
p2 = ggplot(data, aes(x = age, y = y, group = id, color = id)) + 
  geom_line(data = sample, color = "green") +
  geom_line(data = sample, aes(y = predict.1), color = "blue", linetype = "dashed") +
  geom_line(data = sample, aes(y = predict.2), color = "brown", linetype = "dashed") +
  theme_classic()
```


\newpage
## Problem (a)

Here's the figure for the whole population and a random sample of 4:
```{r chunk_sample and plot, message=FALSE}
p
```

\newpage
## Problem (b)

Here's the model summaries:
```{r chunk_b, message=FALSE}
knitr::kable(sum, format = "markdown")
```

Model 4 and 5 give the largest loglikelihood and lowest AIC, provide best fits of the data.

* Model 4:
$$Y_{ki} = \beta_0 + \beta_1\cdot Age_{ki} + \beta_2\cdot Age_{ki}^2+ \beta_3\cdot Age_{ki}^3 + \gamma_{0k} + W_k(T_{ki})+\epsilon_{ki}^*$$
$$Cov[W_k(T_{ki}), W_k(T_{kj})] = \sigma_W^2exp\{-U_{k,ij}/range\}$$ where $U_{k,ij} = |T_{ki}-T_{kj}|$
  
* Model 5:

$$Y_{ki} = \beta_0 + \beta_1\cdot Age_{ki} + \beta_2\cdot Age_{ki}^2+ \beta_3\cdot Age_{ki}^3 + \gamma_{0k} + W_k(T_{ki})+\epsilon_{ki}^*$$
$$Cov[W_k(T_{ki}), W_k(T_{kj})] = \sigma_W^2 (1-n) exp\{-U_{k,ij}/range\}$$ where $n$ denotes the nugget effect.

Here's the coefficient summaries of the two models:

```{r}
knitr::kable(coef, format = "markdown")
```

\newpage
## Problem (c)

Here's the fitted regression curve for the 4 random samples, where green lines are the true Y's, blue lines are the regression curves for model(3) and brown lines for model(2). We can see that model(3) generally provide better fit for the real data.
```{r}
p2
```

## Problem (d)

In model(3), all children have a shared baseline value for FEV.1 regardless of their age. As age increases, the change in their expected FEV.1 value is assumed to be related to age, its quadratic term as well as its cubic term. If the corresponding coefficient is positive, the value of FEV.1 is in positive correlation with this term, and vice versa.

\newpage
## Problem (e)

```{r}
anova(fit6.ML, fit9.ML)
```
I did an ANOVA test on the two models, where the null hypotheses is that the smaller model(model(2)) provide better fit of the data. The p-vlaue of the test was smaller than 0.0001, indicating the null should be rejected under a significance level of 0.05, suggesting that model(3) with more variables actually provide better fit of the data.


## Problem (f)
```{r}
summary(fit6.ML)$tTable
```

I would choose model(3).

* It could be seen in part(c) that model(3) provide better fit of the data, with curves detailedly captured the trend at the begining and end of the real data.

* Given the result of model(3), the p-values of the $age^2$ and $age^3$ term are both far smaller than 0.05, indicating that they both add significantly better explanation for the data. Abandoning them would be unjustified.

* Given the result of the ANOVA test as above, we shouldn't adopt the parsimonious model.
